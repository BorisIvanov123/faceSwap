STEP 1 â€” Detect Face (InsightFace)

You still start with:

Face detection

106 landmarks

Identity embedding (ArcFace 512D)

This is still useful because:

You need strong identity signals

You need consistent character across 30 pages

Stable Diffusion can accept embeddings

STEP 2 â€” Feed Face Embedding into SD Model

Hereâ€™s the new magic:

Use a model like IP-Adapter FaceID (InsightFace variant)

This takes:

The childâ€™s face photo

The ArcFace embedding

A style model (LoRA trained on your bookâ€™s illustrations)

And Stable Diffusion will generate:

The childâ€™s face

Matching hair

Matching expressions

Perfect style

Perfect lighting

All in ONE pass.

That portrait you uploaded earlier is done almost exactly like this.

STEP 3 â€” Provide the Template Page as Conditioning
You feed the page background into SD using:

ControlNet (LineArt / SoftEdge)

OR using inpainting mask where the character goes

So SD will:

Preserve your illustration layout

Preserve body pose

Preserve background

BUT replace the face + hair with the childâ€™s character

And match lighting & style

This makes 30 pages coherent and artistic, NOT Frankensteined.

STEP 4 â€” Generate the Final Page via SD INPAINTING

SD takes:

Template illustration

Mask of the face & hair region

Childâ€™s identity embedding

Style LoRA

Background as reference

Prompt like:

â€œstorybook illustration, soft lighting, magical forest, consistent childrenâ€™s book styleâ€

And produces:

ğŸ¨ A perfectly stylized character
ğŸ§’ With the childâ€™s identity
ğŸ’‡ With matching hair (automatically)
ğŸ“˜ Embedded seamlessly into the page
ğŸ“¸ With consistent lighting & depth

This gives â€œDisney-gradeâ€ personalization.